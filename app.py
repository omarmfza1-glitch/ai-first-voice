# Ø§Ø¨Ø­Ø« Ø¹Ù† Ø¯Ø§Ù„Ø© media_stream ÙÙŠ app.py
# ÙˆØ§Ø³ØªØ¨Ø¯Ù„ Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ø®Ø§Øµ Ø¨Ù€ Google STT (Ù…Ù† Ø§Ù„Ø³Ø·Ø± 338 ØªÙ‚Ø±ÙŠØ¨Ø§Ù‹)
# Ø¨Ù‡Ø°Ø§ Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„ÙƒØ§Ù…Ù„:

@app.websocket("/media")
async def media_stream(ws: WebSocket):
    """WebSocket Ù…Ø­Ø³Ù‘Ù† Ù…Ø¹ Ù…Ø­Ø§Ø¯Ø«Ø© Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„Ù…Ù‚Ø§Ø·Ø¹Ø©"""
    global GOOGLE_STT_AVAILABLE
    
    await ws.accept()
    
    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ call_sid
    query = ws.scope.get("query_string", b"").decode()
    call_sid = ""
    if "callSid=" in query:
        try:
            call_sid = query.split("callSid=")[1].split("&")[0]
        except Exception:
            call_sid = ""
    
    logger.info(f"ğŸ”Œ WebSocket connected: call_sid={call_sid}")
    
    # ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª
    req_iter = None
    stt_task = None
    speech_client = None
    test_task = None
    stt_available = GOOGLE_STT_AVAILABLE
    
    # Google STT Ù…Ø¹ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù…Ø­Ø³Ù‘Ù†Ø© Ù„Ù„Ù…Ù‚Ø§Ø·Ø¹Ø©
    if stt_available and not TEST_MODE:
        try:
            speech_client = speech.SpeechClient()
            
            streaming_config = speech.StreamingRecognitionConfig(
                config=speech.RecognitionConfig(
                    encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
                    sample_rate_hertz=8000,
                    language_code="ar-SA",
                    enable_automatic_punctuation=True,
                    enable_word_time_offsets=False,
                    profanity_filter=False,
                    # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù„Ù„Ù…Ù‚Ø§Ø·Ø¹Ø© Ø§Ù„Ø³Ø±ÙŠØ¹Ø©
                    enable_speaker_diarization=False,
                    speech_contexts=[
                        speech.SpeechContext(
                            phrases=[
                                "Ù†Ø¹Ù…", "Ù„Ø§", "ØªÙˆÙ‚Ù", "Ø§Ù†ØªØ¸Ø±",
                                "Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÙŠÙƒÙ…", "ÙˆØ¹Ù„ÙŠÙƒÙ… Ø§Ù„Ø³Ù„Ø§Ù…",
                                "Ø±ØµÙŠØ¯ÙŠ", "Ø±ØµÙŠØ¯", "Ø§Ù„Ø¨Ø§Ù‚Ø©", "Ø¨Ø§Ù‚ØªÙŠ",
                                "ÙØ§ØªÙˆØ±Ø©", "Ù…Ø´ÙƒÙ„Ø©", "Ø¥Ù†ØªØ±Ù†Øª", "Ø´ÙƒØ±Ø§"
                            ],
                            boost=20.0
                        )
                    ]
                ),
                interim_results=True,  # Ù…Ù‡Ù… Ù„Ù„Ù…Ù‚Ø§Ø·Ø¹Ø©
                single_utterance=False,
            )
            
            req_iter = SpeechRequestIterator()
            
            # Ø¥Ø±Ø³Ø§Ù„ ØµÙˆØª ØµØ§Ù…Øª Ù„ØªØ¬Ù†Ø¨ timeout
            logger.info("Initializing STT with silent audio...")
            silence_samples = 800  # 100ms @ 8kHz
            silence_audio = b'\x00\x00' * silence_samples
            for _ in range(5):
                req_iter.push(silence_audio)
            
            stt_responses = speech_client.streaming_recognize(streaming_config, req_iter)
            stt_task = asyncio.create_task(_consume_stt_with_interruption(stt_responses, lambda: call_sid))
            logger.info("âœ… Google STT initialized with interruption support")
            
        except Exception as e:
            logger.error(f"Failed to initialize STT: {e}")
            stt_available = False
    
    # ÙˆØ¶Ø¹ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±
    if not stt_available or TEST_MODE:
        logger.warning("âš ï¸ Running in TEST MODE or STT unavailable")
        test_task = None
    
    try:
        while True:
            msg = await ws.receive_text()
            try:
                event = json.loads(msg)
            except json.JSONDecodeError:
                logger.warning(f"Invalid JSON received")
                continue
                
            etype = event.get("event")
            
            if etype == "start":
                start = event.get("start", {})
                cp = start.get("customParameters")
                
                if cp:
                    if isinstance(cp, dict):
                        if not call_sid:
                            call_sid = cp.get("callSid", "") or start.get("callSid", "")
                    elif isinstance(cp, str):
                        try:
                            qs = parse_qs(cp)
                            if not call_sid:
                                call_sid = (qs.get("callSid") or [""])[0] or start.get("callSid", "")
                        except Exception as e:
                            logger.warning(f"Failed to parse customParameters: {e}")
                            if not call_sid:
                                call_sid = start.get("callSid", "")
                else:
                    if not call_sid:
                        call_sid = start.get("callSid", "")
                        
                logger.info(f"â–¶ï¸ Stream started: call_sid={call_sid}")
                
                # Ø¨Ø¯Ø¡ Ø§Ù„Ù…Ø­Ø§ÙƒØ§Ø© ÙÙŠ TEST_MODE
                if TEST_MODE and call_sid and not test_task:
                    logger.info(f"ğŸ§ª Starting TEST simulation for {call_sid}")
                    test_task = asyncio.create_task(_simulate_user_input(call_sid, delay=3))
                    
            elif etype == "media":
                media_payload = event.get("media", {})
                b64 = media_payload.get("payload")
                
                if b64 and req_iter:
                    try:
                        ulaw = base64.b64decode(b64)
                        pcm = audioop.ulaw2lin(ulaw, 2)
                        req_iter.push(pcm)
                    except Exception as e:
                        logger.warning(f"Error processing audio: {e}")
                        
            elif etype == "stop":
                logger.info(f"â¹ï¸ Stream stopped: call_sid={call_sid}")
                break
                
    except WebSocketDisconnect:
        logger.info(f"ğŸ”Œ WebSocket disconnected: call_sid={call_sid}")
    except Exception as e:
        logger.exception(f"WebSocket error [{call_sid}]: {e}")
    finally:
        if req_iter:
            req_iter.close()
        if stt_task:
            try:
                await stt_task
            except Exception:
                pass
        if test_task:
            try:
                test_task.cancel()
            except Exception:
                pass
        try:
            await ws.close()
        except Exception:
            pass
        logger.info(f"WebSocket cleanup completed for {call_sid}")


# Ø¯Ø§Ù„Ø© Ù…Ø­Ø³Ù‘Ù†Ø© Ù„Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ù… Ù…Ø¹ Ø¯Ø¹Ù… Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹Ø©
async def _consume_stt_with_interruption(stt_responses, get_call_sid):
    """Ù…Ø¹Ø§Ù„Ø¬Ø© STT Ù…Ø¹ Ø¯Ø¹Ù… Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹Ø© Ø§Ù„ÙÙˆØ±ÙŠØ©"""
    try:
        async for resp in _aiter(stt_responses):
            for result in resp.results:
                # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù…Ø¤Ù‚ØªØ© Ù„Ù„Ù…Ù‚Ø§Ø·Ø¹Ø© Ø§Ù„Ø³Ø±ÙŠØ¹Ø©
                if not result.is_final:
                    interim_text = result.alternatives[0].transcript.strip()
                    if interim_text and len(interim_text) > 2:
                        # ÙƒØ´Ù Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹Ø©
                        logger.debug(f"ğŸ¤ Interim: {interim_text}")
                        
                        # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙŠØ­Ø§ÙˆÙ„ Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹Ø©
                        interrupt_words = ["Ø§Ù†ØªØ¸Ø±", "ØªÙˆÙ‚Ù", "Ù„Ø­Ø¸Ø©", "Ù†Ø¹Ù…", "Ù„Ø§", "ØµØ­", "Ø®Ø·Ø£"]
                        if any(word in interim_text for word in interrupt_words):
                            call_sid = get_call_sid()
                            logger.info(f"ğŸ”´ Interruption detected: {interim_text}")
                            # ÙŠÙ…ÙƒÙ† Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ø±Ø¯ Ø§Ù„Ø­Ø§Ù„ÙŠ Ù‡Ù†Ø§
                            await _handle_interruption(call_sid, interim_text)
                else:
                    # Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
                    transcript = result.alternatives[0].transcript.strip()
                    if transcript:
                        call_sid = get_call_sid()
                        logger.info(f"ğŸ¤ STT Final [{call_sid}]: {transcript}")
                        await _handle_user_turn(call_sid, transcript)
                        
    except Exception as e:
        logger.error(f"STT processing error: {e}")


# Ø¯Ø§Ù„Ø© Ø¬Ø¯ÙŠØ¯Ø© Ù„Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹Ø©
async def _handle_interruption(call_sid: str, text: str):
    """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹Ø© Ø§Ù„ÙÙˆØ±ÙŠØ©"""
    if twilio_client and call_sid:
        try:
            # Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„Ø­Ø§Ù„ÙŠ ÙÙˆØ±Ø§Ù‹
            twiml = """<?xml version="1.0" encoding="UTF-8"?>
<Response>
    <Say language="ar-SA" voice="Polly.Zeina">Ù†Ø¹Ù…ØŒ Ø£Ø³Ù…Ø¹Ùƒ</Say>
    <Redirect method="POST">/voice</Redirect>
</Response>"""
            
            twilio_client.calls(call_sid).update(twiml=twiml)
            logger.info(f"âœ… Interrupted playback for [{call_sid}]")
        except Exception as e:
            logger.error(f"Failed to interrupt: {e}")


# ØªØ­Ø³ÙŠÙ† Ø¯Ø§Ù„Ø© voice_handler Ù„Ù„Ø±Ø³Ø§Ø¦Ù„ Ø§Ù„Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ©
@app.post("/voice")
async def voice_handler(request: Request):
    """Ù…Ø¹Ø§Ù„Ø¬ Twilio Ù…Ø¹ Ø±Ø³Ø§Ø¦Ù„ ØªØ±Ø­ÙŠØ¨ Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ©"""
    form = await request.form()
    call_sid = form.get("CallSid", "")
    from_number = form.get("From", "")
    
    # ØªØ­Ø¯ÙŠØ« Ø­Ø§Ù„Ø© Ø§Ù„Ù…ÙƒØ§Ù„Ù…Ø©
    state = CALL_STATE.get(call_sid)
    if state is None:
        CALL_STATE[call_sid] = {
            "turn": 0,
            "from_number": from_number,
            "start_time": datetime.datetime.utcnow()
        }
        first_turn = True
    else:
        first_turn = state.get("turn", 0) == 0
    
    # Ø¥Ø¹Ø¯Ø§Ø¯ WebSocket URL
    ws_host = urlparse(BASE_URL).netloc or request.url.netloc
    wss_base = f"wss://{ws_host}/media"
    
    # Ø±Ø³Ø§Ù„Ø© ØªØ±Ø­ÙŠØ¨ Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ©
    say_block = ""
    if first_turn:
        # ØªÙˆÙ„ÙŠØ¯ Ø±Ø³Ø§Ù„Ø© ØªØ±Ø­ÙŠØ¨ Ù…Ø®ØªÙ„ÙØ© ÙƒÙ„ Ù…Ø±Ø©
        greeting = await _generate_dynamic_greeting()
        say_block = f"""
  <Say language="ar-SA" voice="Polly.Zeina">{greeting}</Say>"""
    
    # TwiML Ù…Ø¹ Ø¯Ø¹Ù… Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹Ø©
    twiml = f"""<?xml version="1.0" encoding="UTF-8"?>
<Response>
  <Start>
    <Stream url="{wss_base}" track="inbound_track">
      <Parameter name="callSid" value="{call_sid}"/>
    </Stream>
  </Start>{say_block}
  <Pause length="60"/>
</Response>""".strip()
    
    logger.info(f"ğŸ“ Voice handler: call_sid={call_sid}, first_turn={first_turn}")
    return Response(content=twiml, media_type="text/xml; charset=utf-8")


# Ø¯Ø§Ù„Ø© Ø¬Ø¯ÙŠØ¯Ø© Ù„ØªÙˆÙ„ÙŠØ¯ Ø±Ø³Ø§Ø¦Ù„ ØªØ±Ø­ÙŠØ¨ Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ©
async def _generate_dynamic_greeting() -> str:
    """ØªÙˆÙ„ÙŠØ¯ Ø±Ø³Ø§Ù„Ø© ØªØ±Ø­ÙŠØ¨ Ù…Ø®ØªÙ„ÙØ© ÙƒÙ„ Ù…Ø±Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… AI"""
    if not openai_client:
        # Ø±Ø³Ø§Ø¦Ù„ Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ù…ØªÙ†ÙˆØ¹Ø©
        greetings = [
            "Ø£Ù‡Ù„Ø§Ù‹ ÙˆØ³Ù‡Ù„Ø§Ù‹ Ø¨ÙƒÙ… ÙÙŠ Ù…Ø±ÙƒØ² Ø§Ù„Ø§ØªØµØ§Ù„ Ø§Ù„Ø°ÙƒÙŠ. ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ø®Ø¯Ù…ØªÙƒÙ… Ø§Ù„ÙŠÙˆÙ…ØŸ",
            "Ù…Ø±Ø­Ø¨Ø§Ù‹ Ø¨Ùƒ! Ø£Ù†Ø§ Ù…Ø³Ø§Ø¹Ø¯Ùƒ Ø§Ù„Ø°ÙƒÙŠ. Ø¨Ù…Ø§Ø°Ø§ Ø£Ø³ØªØ·ÙŠØ¹ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒØŸ",
            "Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÙŠÙƒÙ… ÙˆØ±Ø­Ù…Ø© Ø§Ù„Ù„Ù‡. ØªÙØ¶Ù„ØŒ ÙƒÙŠÙ Ø£Ù‚Ø¯Ø± Ø£Ø³Ø§Ø¹Ø¯ÙƒØŸ",
            "Ø£Ù‡Ù„Ø§Ù‹ Ø¨Ùƒ ÙÙŠ Ø®Ø¯Ù…Ø© Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡. Ø£Ù†Ø§ Ù‡Ù†Ø§ Ù„Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ ÙÙŠ Ø£ÙŠ Ø§Ø³ØªÙØ³Ø§Ø±.",
            "Ù…Ø³Ø§Ø¡ Ø§Ù„Ø®ÙŠØ± ÙˆØ£Ù‡Ù„Ø§Ù‹ Ø¨Ùƒ. ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ø£Ù† Ø£ÙƒÙˆÙ† ÙÙŠ Ø®Ø¯Ù…ØªÙƒØŸ"
        ]
        import random
        return random.choice(greetings)
    
    try:
        # Ø§Ø³ØªØ®Ø¯Ø§Ù… GPT Ù„ØªÙˆÙ„ÙŠØ¯ Ø±Ø³Ø§Ù„Ø© ØªØ±Ø­ÙŠØ¨ ÙØ±ÙŠØ¯Ø©
        current_time = datetime.datetime.now()
        time_of_day = "ØµØ¨Ø§Ø­" if current_time.hour < 12 else "Ù…Ø³Ø§Ø¡" if current_time.hour < 18 else "Ù…Ø³Ø§Ø¡"
        
        prompt = f"""Ø£Ù†Øª Ù…ÙˆØ¸Ù Ø®Ø¯Ù…Ø© Ø¹Ù…Ù„Ø§Ø¡ ÙˆØ¯ÙˆØ¯ ÙÙŠ Ø´Ø±ÙƒØ© Ø§ØªØµØ§Ù„Ø§Øª.
Ø§ÙƒØªØ¨ Ø±Ø³Ø§Ù„Ø© ØªØ±Ø­ÙŠØ¨ Ù‚ØµÙŠØ±Ø© (10-15 ÙƒÙ„Ù…Ø©) Ù„Ù„Ù…ØªØµÙ„.
Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ø¢Ù†: {time_of_day}
ÙƒÙ† ÙˆØ¯ÙˆØ¯Ø§Ù‹ ÙˆÙ…Ø­ØªØ±ÙØ§Ù‹. ØºÙŠÙ‘Ø± Ø§Ù„ØµÙŠØºØ© ÙƒÙ„ Ù…Ø±Ø©.
Ù„Ø§ ØªÙƒØ±Ø± Ù†ÙØ³ Ø§Ù„Ø£Ø³Ù„ÙˆØ¨. ÙƒÙ† Ù…Ø¨Ø¯Ø¹Ø§Ù‹.
Ø§Ù„Ø±Ø³Ø§Ù„Ø©:"""
        
        response = openai_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.9,  # Ø¹Ø§Ù„ÙŠØ© Ù„Ù„ØªÙ†ÙˆØ¹
            max_tokens=50
        )
        
        greeting = response.choices[0].message.content.strip()
        logger.info(f"ğŸ¨ Dynamic greeting: {greeting}")
        return greeting
        
    except Exception as e:
        logger.error(f"Failed to generate dynamic greeting: {e}")
        return "Ù…Ø±Ø­Ø¨Ø§Ù‹ Ø¨ÙƒÙ… ÙÙŠ Ù…Ø±ÙƒØ² Ø§Ù„Ø§ØªØµØ§Ù„ Ø§Ù„Ø°ÙƒÙŠ. ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒÙ…ØŸ"
